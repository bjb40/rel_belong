
@article{lynch_new_2005,
	title = {A new approach to estimating life tables with covariates and constructing interval estimates of life table quantities},
	volume = {35},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.0081-1750.2006.00168.x/abstract},
	number = {1},
	urldate = {2014-03-03},
	journal = {Sociological Methodology},
	author = {Lynch, Scott M. and Brown, J. Scott},
	year = {2005},
	pages = {177--225},
	file = {Lynch-Brown2005SociolMethodologyArticle.pdf:C\:\\Users\\bjb40\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\jjhehss7.default\\zotero\\storage\\HZR97PRV\\Lynch-Brown2005SociolMethodologyArticle.pdf:application/pdf}
}

@article{albert_bayesian_1993,
	title = {Bayesian {Analysis} of {Binary} and {Polychotomous} {Response} {Data}},
	volume = {88},
	issn = {0162-1459},
	url = {http://www.tandfonline.com/doi/abs/10.1080/01621459.1993.10476321},
	doi = {10.1080/01621459.1993.10476321},
	abstract = {A vast literature in statistics, biometrics, and econometrics is concerned with the analysis of binary and polychotomous response data. The classical approach fits a categorical response regression model using maximum likelihood, and inferences about the model are based on the associated asymptotic theory. The accuracy of classical confidence statements is questionable for small sample sizes. In this article, exact Bayesian methods for modeling categorical response data are developed using the idea of data augmentation. The general approach can be summarized as follows. The probit regression model for binary outcomes is seen to have an underlying normal regression structure on latent continuous data. Values of the latent data can be simulated from suitable truncated normal distributions. If the latent data are known, then the posterior distribution of the parameters can be computed using standard results for normal linear models. Draws from this posterior are used to sample new latent data, and the process is iterated with Gibbs sampling. This data augmentation approach provides a general framework for analyzing binary regression models. It leads to the same simplification achieved earlier for censored regression models. Under the proposed framework, the class of probit regression models can be enlarged by using mixtures of normal distributions to model the latent data. In this normal mixture class, one can investigate the sensitivity of the parameter estimates to the choice of “link function,” which relates the linear regression estimate to the fitted probabilities. In addition, this approach allows one to easily fit Bayesian hierarchical models. One specific model considered here reflects the belief that the vector of regression coefficients lies on a smaller dimension linear subspace. The methods can also be generalized to multinomial response models with J {\textgreater} 2 categories. In the ordered multinomial model, the J categories are ordered and a model is written linking the cumulative response probabilities with the linear regression structure. In the unordered multinomial model, the latent variables have a multivariate normal distribution with unknown variance-covariance matrix. For both multinomial models, the data augmentation method combined with Gibbs sampling is outlined. This approach is especially attractive for the multivariate probit model, where calculating the likelihood can be difficult.},
	number = {422},
	urldate = {2015-08-03},
	journal = {Journal of the American Statistical Association},
	author = {Albert, James H. and Chib, Siddhartha},
	month = jun,
	year = {1993},
	pages = {669--679},
	file = {Snapshot:C\:\\Users\\bjb40\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\jjhehss7.default\\zotero\\storage\\Q6PI8KWM\\01621459.1993.html:text/html}
}

@article{zhang_bayesian_2008,
	title = {Bayesian analysis of multivariate nominal measures using multivariate multinomial probit models},
	volume = {52},
	issn = {0167-9473},
	url = {http://www.sciencedirect.com/science/article/pii/S0167947307004690},
	doi = {10.1016/j.csda.2007.12.012},
	abstract = {The multinomial probit model has emerged as a useful framework for modeling nominal categorical data, but extending such models to multivariate measures presents computational challenges. Following a Bayesian paradigm, we use a Markov chain Monte Carlo (MCMC) method to analyze multivariate nominal measures through multivariate multinomial probit models. As with a univariate version of the model, identification of model parameters requires restrictions on the covariance matrix of the latent variables that are introduced to define the probit specification. To sample the covariance matrix with restrictions within the MCMC procedure, we use a parameter-extended Metropolis–Hastings algorithm that incorporates artificial variance parameters to transform the problem into a set of simpler tasks including sampling an unrestricted covariance matrix. The parameter-extended algorithm also allows for flexible prior distributions on covariance matrices. The prior specification in the method described here generalizes earlier approaches to analyzing univariate nominal data, and the multivariate correlation structure in the method described here generalizes the autoregressive structure proposed in previous multiperiod multinomial probit models. Our methodology is illustrated through a simulated example and an application to a cancer-control study aiming to achieve early detection of breast cancer.},
	number = {7},
	urldate = {2015-08-03},
	journal = {Computational Statistics \& Data Analysis},
	author = {Zhang, Xiao and Boscardin, W. John and Belin, Thomas R.},
	month = mar,
	year = {2008},
	pages = {3697--3708},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\bjb40\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\jjhehss7.default\\zotero\\storage\\GIDQBGXA\\Zhang et al. - 2008 - Bayesian analysis of multivariate nominal measures.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\bjb40\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\jjhehss7.default\\zotero\\storage\\74CH3KUQ\\S0167947307004690.html:text/html}
}

@article{lynch_bayesian_2004,
	title = {Bayesian {Posterior} {Predictive} {Checks} for {Complex} {Models}},
	volume = {32},
	issn = {0049-1241, 1552-8294},
	url = {http://smr.sagepub.com.proxy.lib.duke.edu/content/32/3/301},
	doi = {10.1177/0049124103257303},
	abstract = {In sociological research, it is often difficult to compare nonnested models and to evaluate the fit of models in which outcome variables are not normally distributed. In this article, the authors demonstrate the utility of Bayesian posterior predictive distributions specifically, as well as a Bayesian approach to modeling more generally, in tackling these issues. First, they review the Bayesian approach to statistics and computation. Second, they discuss the evaluation of model fit in a bivariate probit model. Third, they discuss comparing fixed- and random-effects hierarchical linear models. Both examples highlight the use of Bayesian posterior predictive distributions beyond these particular cases.},
	language = {en},
	number = {3},
	urldate = {2015-03-12},
	journal = {Sociological Methods \& Research},
	author = {Lynch, Scott M. and Western, Bruce},
	month = feb,
	year = {2004},
	keywords = {Bayesian approach, Bayesian posterior predictive distributions, model fit, statistics},
	pages = {301--335}
}

@book{kruschke_doing_2014,
	title = {Doing {Bayesian} {Data} {Analysis}: {A} {Tutorial} with {R}, {JAGS}, and {Stan}},
	isbn = {978-0-12-405916-0},
	shorttitle = {Doing {Bayesian} {Data} {Analysis}},
	abstract = {There is an explosion of interest in Bayesian statistics, primarily because recently created computational methods have finally made Bayesian analysis obtainable to a wide audience. Doing Bayesian Data Analysis: A Tutorial with R, JAGS, and Stan provides an accessible approach to Bayesian data analysis, as material is explained clearly with concrete examples. The book begins with the basics, including essential concepts of probability and random sampling, and gradually progresses to advanced hierarchical modeling methods for realistic data. Included are step-by-step instructions on how to conduct Bayesian data analyses in the popular and free software R and WinBugs. This book is intended for first-year graduate students or advanced undergraduates. It provides a bridge between undergraduate training and modern Bayesian methods for data analysis, which is becoming the accepted research standard. Knowledge of algebra and basic calculus is a prerequisite. New to this Edition (partial list): There are all new programs in JAGS and Stan. The new programs are designed to be much easier to use than the scripts in the first edition. In particular, there are now compact high-level scripts that make it easy to run the programs on your own data sets. This new programming was a major undertaking by itself.The introductory Chapter 2, regarding the basic ideas of how Bayesian inference re-allocates credibility across possibilities, is completely rewritten and greatly expanded.There are completely new chapters on the programming languages R (Ch. 3), JAGS (Ch. 8), and Stan (Ch. 14). The lengthy new chapter on R includes explanations of data files and structures such as lists and data frames, along with several utility functions. (It also has a new poem that I am particularly pleased with.) The new chapter on JAGS includes explanation of the RunJAGS package which executes JAGS on parallel computer cores. The new chapter on Stan provides a novel explanation of the concepts of Hamiltonian Monte Carlo. The chapter on Stan also explains conceptual differences in program flow between it and JAGS.Chapter 5 on Bayes’ rule is greatly revised, with a new emphasis on how Bayes’ rule re-allocates credibility across parameter values from prior to posterior. The material on model comparison has been removed from all the early chapters and integrated into a compact presentation in Chapter 10.What were two separate chapters on the Metropolis algorithm and Gibbs sampling have been consolidated into a single chapter on MCMC methods (as Chapter 7). There is extensive new material on MCMC convergence diagnostics in Chapters 7 and 8. There are explanations of autocorrelation and effective sample size. There is also exploration of the stability of the estimates of the HDI limits. New computer programs display the diagnostics, as well.Chapter 9 on hierarchical models includes extensive new and unique material on the crucial concept of shrinkage, along with new examples.All the material on model comparison, which was spread across various chapters in the first edition, in now consolidated into a single focused chapter (Ch. 10) that emphasizes its conceptualization as a case of hierarchical modeling.Chapter 11 on null hypothesis significance testing is extensively revised. It has new material for introducing the concept of sampling distribution. It has new illustrations of sampling distributions for various stopping rules, and for multiple tests.Chapter 12, regarding Bayesian approaches to null value assessment, has new material about the region of practical equivalence (ROPE), new examples of accepting the null value by Bayes factors, and new explanation of the Bayes factor in terms of the Savage-Dickey method.},
	language = {en},
	publisher = {Academic Press},
	author = {Kruschke, John},
	month = nov,
	year = {2014},
	keywords = {Mathematics / Applied, Mathematics / General}
}

@article{land_estimating_1994,
	title = {Estimating {Increment}-{Decrement} {Life} {Tables} with {Multiple} {Covariates} from {Panel} {Data}: {The} {Case} of {Active} {Life} {Expectancy}*},
	volume = {31},
	issn = {0070-3370, 1533-7790},
	shorttitle = {Estimating {Increment}-{Decrement} {Life} {Tables} with {Multiple} {Covariates} from {Panel} {Data}},
	url = {http://link.springer.com/article/10.2307/2061887},
	doi = {10.2307/2061887},
	language = {en},
	number = {2},
	urldate = {2015-09-07},
	journal = {Demography},
	author = {Land, Kenneth C. and Guralnik, Jack M. and Blazer, Dan G.},
	month = may,
	year = {1994},
	keywords = {Demography, Geography (general), Medicine/Public Health, general, Population Economics, Sociology},
	pages = {297--319},
	file = {Full Text PDF:C\:\\Users\\bjb40\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\jjhehss7.default\\zotero\\storage\\2ZNAHG6G\\Land et al. - 1994 - Estimating Increment-Decrement Life Tables with Mu.pdf:application/pdf;Snapshot:C\:\\Users\\bjb40\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\jjhehss7.default\\zotero\\storage\\CSSZVPVU\\2061887.html:text/html}
}

@book{lynch_introduction_2007,
	address = {New York},
	title = {Introduction to {Applied} {Bayesian} {Statistics} and {Estimation} for {Social} {Scientists}},
	isbn = {978-0-387-71264-2},
	abstract = {This book outlines Bayesian statistical analysis in great detail, from the development of a model through the process of making statistical inference. The key feature of this book is that it covers models that are most commonly used in social science research - including the linear regression model, generalized linear models, hierarchical models, and multivariate regression models - and it thoroughly develops each real-data example in painstaking detail.},
	language = {English},
	publisher = {Springer},
	author = {Lynch, Scott M.},
	month = aug,
	year = {2007}
}

@article{lynch_obtaining_2010,
	title = {Obtaining multistate life table distributions for highly refined subpopulations from cross-sectional data: {A} {Bayesian} extension of {Sullivan}’s method},
	volume = {47},
	shorttitle = {Obtaining multistate life table distributions for highly refined subpopulations from cross-sectional data},
	url = {http://link.springer.com/article/10.1007/BF03213739},
	number = {4},
	urldate = {2014-03-03},
	journal = {Demography},
	author = {Lynch, Scott M. and Brown, J. Scott},
	year = {2010},
	pages = {1053--1077},
	file = {Lynch-Brown2010DemographyArtilce.pdf:C\:\\Users\\bjb40\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\jjhehss7.default\\zotero\\storage\\WB7EJFMB\\Lynch-Brown2010DemographyArtilce.pdf:application/pdf}
}